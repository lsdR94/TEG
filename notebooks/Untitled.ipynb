{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T15:15:40.927473Z",
     "start_time": "2019-08-11T15:15:39.038541Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import segyio\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T15:15:41.306129Z",
     "start_time": "2019-08-11T15:15:41.289359Z"
    }
   },
   "outputs": [],
   "source": [
    "s_path = os.path.join(\"..\", \"data\", \"MS2990-2200_3000-2210.sgy\")\n",
    "s_path1 = os.path.join(\"..\", \"data\", \"MS2950-2180_3000-2230.sgy\")\n",
    "s_path2 = os.path.join(\"..\", \"data\", \"FS2950-2180_3000-2230 (copia).sgy\")\n",
    "new_seismic = os.path.join(\"..\", \"data\", \"NMF2950-2180_3000-2230.sgy\")\n",
    "smallps = os.path.join(\"..\", \"data\", \"small-ps.sgy\")\n",
    "gather_path = [s_path, s_path1, s_path2]\n",
    "\n",
    "angle_bet_gathers = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T15:15:43.027573Z",
     "start_time": "2019-08-11T15:15:42.703907Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'f' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-fb00f20a3ee0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'f' is not defined"
     ]
    }
   ],
   "source": [
    "    print(f.iline[1,1])\n",
    "    print(\" \")\n",
    "    print(f.iline[1,2])\n",
    "    print(\" \")\n",
    "    print(f.iline[1])\n",
    "    print(\" \")\n",
    "    print(f.offsets)\n",
    "    print(f.trace[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T15:18:15.471482Z",
     "start_time": "2019-08-11T15:18:15.452885Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{TRACE_SEQUENCE_LINE: 0, TRACE_SEQUENCE_FILE: 0, FieldRecord: 0, TraceNumber: 0, EnergySourcePoint: 0, CDP: 0, CDP_TRACE: 0, TraceIdentificationCode: 0, NSummedTraces: 0, NStackedTraces: 0, DataUse: 0, offset: 2, ReceiverGroupElevation: 0, SourceSurfaceElevation: 0, SourceDepth: 0, ReceiverDatumElevation: 0, SourceDatumElevation: 0, SourceWaterDepth: 0, GroupWaterDepth: 0, ElevationScalar: 0, SourceGroupScalar: 0, SourceX: 0, SourceY: 0, GroupX: 0, GroupY: 0, CoordinateUnits: 0, WeatheringVelocity: 0, SubWeatheringVelocity: 0, SourceUpholeTime: 0, GroupUpholeTime: 0, SourceStaticCorrection: 0, GroupStaticCorrection: 0, TotalStaticApplied: 0, LagTimeA: 0, LagTimeB: 0, DelayRecordingTime: 0, MuteTimeStart: 0, MuteTimeEND: 0, TRACE_SAMPLE_COUNT: 0, TRACE_SAMPLE_INTERVAL: 0, GainType: 0, InstrumentGainConstant: 0, InstrumentInitialGain: 0, Correlated: 0, SweepFrequencyStart: 0, SweepFrequencyEnd: 0, SweepLength: 0, SweepType: 0, SweepTraceTaperLengthStart: 0, SweepTraceTaperLengthEnd: 0, TaperType: 0, AliasFilterFrequency: 0, AliasFilterSlope: 0, NotchFilterFrequency: 0, NotchFilterSlope: 0, LowCutFrequency: 0, HighCutFrequency: 0, LowCutSlope: 0, HighCutSlope: 0, YearDataRecorded: 0, DayOfYear: 0, HourOfDay: 0, MinuteOfHour: 0, SecondOfMinute: 0, TimeBaseCode: 0, TraceWeightingFactor: 0, GeophoneGroupNumberRoll1: 0, GeophoneGroupNumberFirstTraceOrigField: 0, GeophoneGroupNumberLastTraceOrigField: 0, GapSize: 0, OverTravel: 0, CDP_X: 0, CDP_Y: 0, INLINE_3D: 4, CROSSLINE_3D: 3, ShotPoint: 0, ShotPointScalar: 0, TraceValueMeasurementUnit: 0, TransductionConstantMantissa: 0, TransductionConstantPower: 0, TransductionUnit: 0, TraceIdentifier: 0, ScalarTraceHeader: 0, SourceType: 0, SourceEnergyDirectionMantissa: 0, SourceEnergyDirectionExponent: 0, SourceMeasurementMantissa: 0, SourceMeasurementExponent: 0, SourceMeasurementUnit: 0}\n",
      "[1 2]\n",
      "[101.01999  101.020004 101.02002  101.02002  101.020035 101.02005\n",
      " 101.02005  101.020065 101.02008  101.02008 ]\n"
     ]
    }
   ],
   "source": [
    "with segyio.open(smallps, \"r\") as f:\n",
    "    print(f.header[23])\n",
    "    #print(f.attributes(segyio.TraceField.CDP_Y)[0])\n",
    "    print(f.offsets)\n",
    "    for angle\n",
    "    print(f.gather[inline_n, xline, angle])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging sgys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T15:15:46.884345Z",
     "start_time": "2019-08-11T15:15:46.878652Z"
    }
   },
   "outputs": [],
   "source": [
    "from shutil import copyfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T15:15:47.453947Z",
     "start_time": "2019-08-11T15:15:47.450218Z"
    }
   },
   "outputs": [],
   "source": [
    "        #s.header.iline[:] = {37: 12}\n",
    "        #s.header.iline[:,24] = {37: 24}\n",
    "        #s.header.iline[:,36] = {37: 36}\n",
    "        #s.header.offset = offsts\n",
    "        #print(s.header[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# change the offset in the gathers\n",
    "to change the offser header then to merge to see what the fuck is happening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T15:15:50.809920Z",
     "start_time": "2019-08-11T15:15:50.164772Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{TRACE_SEQUENCE_LINE: 1, TRACE_SEQUENCE_FILE: 1, FieldRecord: 2990, TraceNumber: 0, EnergySourcePoint: 0, CDP: 2200, CDP_TRACE: 0, TraceIdentificationCode: 1, NSummedTraces: 0, NStackedTraces: 0, DataUse: 1, offset: 0, ReceiverGroupElevation: 0, SourceSurfaceElevation: 0, SourceDepth: 0, ReceiverDatumElevation: 0, SourceDatumElevation: 0, SourceWaterDepth: 0, GroupWaterDepth: 0, ElevationScalar: 0, SourceGroupScalar: -10, SourceX: 4240817, SourceY: 84900492, GroupX: 0, GroupY: 0, CoordinateUnits: 1, WeatheringVelocity: 0, SubWeatheringVelocity: 0, SourceUpholeTime: 0, GroupUpholeTime: 0, SourceStaticCorrection: 0, GroupStaticCorrection: 0, TotalStaticApplied: 0, LagTimeA: 0, LagTimeB: 0, DelayRecordingTime: 0, MuteTimeStart: 0, MuteTimeEND: 0, TRACE_SAMPLE_COUNT: 1501, TRACE_SAMPLE_INTERVAL: 4000, GainType: 0, InstrumentGainConstant: 0, InstrumentInitialGain: 0, Correlated: 0, SweepFrequencyStart: 0, SweepFrequencyEnd: 0, SweepLength: 0, SweepType: 0, SweepTraceTaperLengthStart: 0, SweepTraceTaperLengthEnd: 0, TaperType: 0, AliasFilterFrequency: 0, AliasFilterSlope: 0, NotchFilterFrequency: 0, NotchFilterSlope: 0, LowCutFrequency: 0, HighCutFrequency: 0, LowCutSlope: 0, HighCutSlope: 0, YearDataRecorded: 0, DayOfYear: 0, HourOfDay: 0, MinuteOfHour: 0, SecondOfMinute: 0, TimeBaseCode: 0, TraceWeightingFactor: 0, GeophoneGroupNumberRoll1: 0, GeophoneGroupNumberFirstTraceOrigField: 0, GeophoneGroupNumberLastTraceOrigField: 0, GapSize: 0, OverTravel: 0, CDP_X: 4240817, CDP_Y: 84900492, INLINE_3D: 2990, CROSSLINE_3D: 2200, ShotPoint: 1, ShotPointScalar: 0, TraceValueMeasurementUnit: 0, TransductionConstantMantissa: 0, TransductionConstantPower: 0, TransductionUnit: 0, TraceIdentifier: 0, ScalarTraceHeader: 0, SourceType: 0, SourceEnergyDirectionMantissa: 0, SourceEnergyDirectionExponent: 0, SourceMeasurementMantissa: 0, SourceMeasurementExponent: 0, SourceMeasurementUnit: 0}\n",
      "{TRACE_SEQUENCE_LINE: 1, TRACE_SEQUENCE_FILE: 1, FieldRecord: 2950, TraceNumber: 0, EnergySourcePoint: 0, CDP: 2180, CDP_TRACE: 0, TraceIdentificationCode: 1, NSummedTraces: 0, NStackedTraces: 0, DataUse: 1, offset: 0, ReceiverGroupElevation: 0, SourceSurfaceElevation: 0, SourceDepth: 0, ReceiverDatumElevation: 0, SourceDatumElevation: 0, SourceWaterDepth: 0, GroupWaterDepth: 0, ElevationScalar: 0, SourceGroupScalar: -10, SourceX: 4237911, SourceY: 84893139, GroupX: 0, GroupY: 0, CoordinateUnits: 1, WeatheringVelocity: 0, SubWeatheringVelocity: 0, SourceUpholeTime: 0, GroupUpholeTime: 0, SourceStaticCorrection: 0, GroupStaticCorrection: 0, TotalStaticApplied: 0, LagTimeA: 0, LagTimeB: 0, DelayRecordingTime: 0, MuteTimeStart: 0, MuteTimeEND: 0, TRACE_SAMPLE_COUNT: 1501, TRACE_SAMPLE_INTERVAL: 4000, GainType: 0, InstrumentGainConstant: 0, InstrumentInitialGain: 0, Correlated: 0, SweepFrequencyStart: 0, SweepFrequencyEnd: 0, SweepLength: 0, SweepType: 0, SweepTraceTaperLengthStart: 0, SweepTraceTaperLengthEnd: 0, TaperType: 0, AliasFilterFrequency: 0, AliasFilterSlope: 0, NotchFilterFrequency: 0, NotchFilterSlope: 0, LowCutFrequency: 0, HighCutFrequency: 0, LowCutSlope: 0, HighCutSlope: 0, YearDataRecorded: 0, DayOfYear: 0, HourOfDay: 0, MinuteOfHour: 0, SecondOfMinute: 0, TimeBaseCode: 0, TraceWeightingFactor: 0, GeophoneGroupNumberRoll1: 0, GeophoneGroupNumberFirstTraceOrigField: 0, GeophoneGroupNumberLastTraceOrigField: 0, GapSize: 0, OverTravel: 0, CDP_X: 4237911, CDP_Y: 84893139, INLINE_3D: 2950, CROSSLINE_3D: 2180, ShotPoint: 1, ShotPointScalar: 0, TraceValueMeasurementUnit: 0, TransductionConstantMantissa: 0, TransductionConstantPower: 0, TransductionUnit: 0, TraceIdentifier: 0, ScalarTraceHeader: 0, SourceType: 0, SourceEnergyDirectionMantissa: 0, SourceEnergyDirectionExponent: 0, SourceMeasurementMantissa: 0, SourceMeasurementExponent: 0, SourceMeasurementUnit: 0}\n",
      "{TRACE_SEQUENCE_LINE: 1, TRACE_SEQUENCE_FILE: 1, FieldRecord: 2950, TraceNumber: 0, EnergySourcePoint: 0, CDP: 2180, CDP_TRACE: 0, TraceIdentificationCode: 1, NSummedTraces: 0, NStackedTraces: 0, DataUse: 1, offset: 0, ReceiverGroupElevation: 0, SourceSurfaceElevation: 0, SourceDepth: 0, ReceiverDatumElevation: 0, SourceDatumElevation: 0, SourceWaterDepth: 0, GroupWaterDepth: 0, ElevationScalar: 0, SourceGroupScalar: -10, SourceX: 4237911, SourceY: 84893139, GroupX: 0, GroupY: 0, CoordinateUnits: 1, WeatheringVelocity: 0, SubWeatheringVelocity: 0, SourceUpholeTime: 0, GroupUpholeTime: 0, SourceStaticCorrection: 0, GroupStaticCorrection: 0, TotalStaticApplied: 0, LagTimeA: 0, LagTimeB: 0, DelayRecordingTime: 0, MuteTimeStart: 0, MuteTimeEND: 0, TRACE_SAMPLE_COUNT: 1501, TRACE_SAMPLE_INTERVAL: 4000, GainType: 0, InstrumentGainConstant: 0, InstrumentInitialGain: 0, Correlated: 0, SweepFrequencyStart: 0, SweepFrequencyEnd: 0, SweepLength: 0, SweepType: 0, SweepTraceTaperLengthStart: 0, SweepTraceTaperLengthEnd: 0, TaperType: 0, AliasFilterFrequency: 0, AliasFilterSlope: 0, NotchFilterFrequency: 0, NotchFilterSlope: 0, LowCutFrequency: 0, HighCutFrequency: 0, LowCutSlope: 0, HighCutSlope: 0, YearDataRecorded: 0, DayOfYear: 0, HourOfDay: 0, MinuteOfHour: 0, SecondOfMinute: 0, TimeBaseCode: 0, TraceWeightingFactor: 0, GeophoneGroupNumberRoll1: 0, GeophoneGroupNumberFirstTraceOrigField: 0, GeophoneGroupNumberLastTraceOrigField: 0, GapSize: 0, OverTravel: 0, CDP_X: 4237911, CDP_Y: 84893139, INLINE_3D: 2950, CROSSLINE_3D: 2180, ShotPoint: 1, ShotPointScalar: 0, TraceValueMeasurementUnit: 0, TransductionConstantMantissa: 0, TransductionConstantPower: 0, TransductionUnit: 0, TraceIdentifier: 0, ScalarTraceHeader: 0, SourceType: 0, SourceEnergyDirectionMantissa: 0, SourceEnergyDirectionExponent: 0, SourceMeasurementMantissa: 0, SourceMeasurementExponent: 0, SourceMeasurementUnit: 0}\n"
     ]
    }
   ],
   "source": [
    "for file in gather_path:\n",
    "    with segyio.open(file, \"r+\") as f:\n",
    "        print(f.header[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source1: https://github.com/equinor/segyio/blob/master/python/examples/make-file.py\n",
    "# source2: https://github.com/equinor/segyio/blob/master/python/segyio/tracefield.py\n",
    "\n",
    "# declaring offsets to set\n",
    "offsts = np.array([12, 24, 36])\n",
    "\n",
    "# Initializing files\n",
    "with segyio.open(s_path) as f, segyio.open(s_path1) as g, segyio.open(s_path2) as h:\n",
    "    spec = segyio.spec()\n",
    "    spec.sorting = f.sorting\n",
    "    spec.format = f.format\n",
    "    spec.samples = f.samples\n",
    "    spec.ilines = f.ilines\n",
    "    spec.xlines = f.xlines\n",
    "    spec.offsets = offsts\n",
    "    \n",
    "    # Initializing the merge\n",
    "    with segyio.create(new_seismic, spec) as s:\n",
    "        \n",
    "        # Trace in the merge\n",
    "        tr = 0\n",
    "        # Trace in the original\n",
    "        tr1 = 0\n",
    "        # For loop to set parameters according to the seismic lines and offset\n",
    "        for il in spec.ilines:\n",
    "            for xl in spec.xlines:\n",
    "                for offset in spec.offsets:\n",
    "                    # Assigning headers [byte]\n",
    "                    s.header[tr] = {segyio.su.tracl  : f.header[tr1][1],\n",
    "                                    segyio.su.tracr  : f.header[tr1][5],\n",
    "                                    segyio.su.fldr   : f.header[tr1][9],\n",
    "                                    segyio.su.cdp    : f.header[tr1][21],\n",
    "                                    segyio.su.cdpt   : f.header[tr1][25],\n",
    "                                    segyio.su.offset : offset, # 37\n",
    "                                    segyio.su.scalco : f.header[tr1][71],\n",
    "                                    segyio.su.ns     : f.header[tr1][115],\n",
    "                                    segyio.su.dt     : f.header[tr1][117],\n",
    "                                    segyio.su.cdpx   : f.header[tr1][181],\n",
    "                                    segyio.su.cdpy   : f.header[tr1][185],\n",
    "                                    segyio.su.iline  : il,  # 189\n",
    "                                    segyio.su.xline  : xl}  # 193\n",
    "                    s.trace[tr] = f.trace[tr1]\n",
    "                    tr += 1\n",
    "                tr1 += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ True  True  True ...  True  True  True]]\n",
      "[[ True  True  True ...  True  True  True]]\n"
     ]
    }
   ],
   "source": [
    "with segyio.open(new_seismic, \"r\") as f, segyio.open(s_path1) as g:\n",
    "    #print(f.header[0])\n",
    "    #print(g.header[0][9])\n",
    "    #print(g.header[0])\n",
    "    #print(f.offsets)\n",
    "    print(g.gather[2950, 2180] == g.trace[0])\n",
    "    print(g.gather[2951, 2180] == g.trace[56])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "trace index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-a74939b9dbfe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moffsets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moffsts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msegyio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_seismic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5201\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtracecount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tesis/lib/python3.7/site-packages/segyio/trace.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m    589\u001b[0m         \"\"\"\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m             \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrapindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    592\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mField\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraceno\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msegy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tesis/lib/python3.7/site-packages/segyio/trace.py\u001b[0m in \u001b[0;36mwrapindex\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;31m# int-like.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'trace index out of range'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: trace index out of range"
     ]
    }
   ],
   "source": [
    "offsts = np.array([12])\n",
    "with segyio.open(s_path) as f, segyio.open(s_path1) as g, segyio.open(s_path2) as h:\n",
    "    spec = segyio.spec()\n",
    "    spec.sorting = f.sorting\n",
    "    spec.format = f.format\n",
    "    spec.samples = f.samples\n",
    "    # CALCULATED THROUGH THE OFFSET ARRAY\n",
    "    #spec.tracecount = f.tracecount\n",
    "    spec.ilines = f.ilines\n",
    "    spec.xlines = f.xlines\n",
    "    spec.offsets = offsts\n",
    "    with segyio.create(new_seismic, spec) as s:\n",
    "        print(s.header[5201])\n",
    "        print(s.tracecount)\n",
    "        \n",
    "        # Testing things\n",
    "        \n",
    "        # if the data is prestack, f.offsets should return an np.array != 0\n",
    "        #print(s.offsets)\n",
    "        # if the data is prestack, then the header[0][37] != 0 // header[0][37] == 3\n",
    "        #print(s.header[0][37] == 3)\n",
    "        # Trace[0] should give the first trace the function finds... theorically it's f.iline[2950,12]\n",
    "        #print(s.trace[0][750] == s.iline[2950,12][0][750])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "I/O operation failed on trace header 0, likely corrupted file",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-4cf9ffcc24e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0msegyio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_seismic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tesis/lib/python3.7/site-packages/segyio/open.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(filename, mode, iline, xline, strict, ignore_geometry, endian)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         \u001b[0mdt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msegyio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfallback_dt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4000.0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m1000.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m         \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msegyio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTraceField\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDelayRecordingTime\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'samplecount'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tesis/lib/python3.7/site-packages/segyio/tools.py\u001b[0m in \u001b[0;36mdt\u001b[0;34m(f, fallback_dt)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \"\"\"\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxfd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetdt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfallback_dt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: I/O operation failed on trace header 0, likely corrupted file"
     ]
    }
   ],
   "source": [
    "with segyio.open(new_seismic, \"r\") as f:\n",
    "    print(f.header[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "with segyio.open(s_path) as segy, segyio.open(s_path1) as segy1, segyio.open(s_path2) as segy2:\n",
    "    spec = segyio.spec()\n",
    "    spec.sorting = segy.sorting\n",
    "    spec.format = segy.format\n",
    "    spec.samples = segy.samples\n",
    "    spec.ilines = segy.ilines\n",
    "    spec.xlines = segy.xlines\n",
    "    spec.offsets[:] = np.array([12, 24, 36])\n",
    "    with segyio.create(new_seismic, spec) as nsegy:\n",
    "        nsegy.text[0] = segy.text[0]\n",
    "        nsegy.bin = segy.bin\n",
    "        nsegy.header = segy.header\n",
    "        nsegy.header.iline[1:3, 2] = {1: 13}\n",
    "\n",
    "        nsegy.iline[:,12] = segy.iline[:]\n",
    "        nsegy.iline[:,24] = segy1.iline[:]\n",
    "        nsegy.iline[:,36] = segy2.iline[:]\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "argument of type 'spec' is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-657dc1085efa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0msegyio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_seismic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnsegy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnsegy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/test/lib/python3.7/site-packages/segyio/open.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(filename, mode, iline, xline, strict, ignore_geometry, endian)\u001b[0m\n\u001b[1;32m    142\u001b[0m     \"\"\"\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m         \u001b[0mproblem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'w in mode would truncate the file'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0msolution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'use r+ to open in read-write'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: argument of type 'spec' is not iterable"
     ]
    }
   ],
   "source": [
    "with segyio.open(new_seismic, spec) as nsegy:\n",
    "    print(nsegy.header[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "with segyio.open(s_path) as segy, segyio.open(s_path1) as segy1, segyio.open(s_path2) as segy2:\n",
    "    spec = segyio.spec()\n",
    "    spec.sorting = segy.sorting\n",
    "    spec.format = segy.format\n",
    "    spec.samples = segy.samples\n",
    "    spec.ilines = segy.ilines\n",
    "    spec.xlines = segy.xlines\n",
    "    spec.offsets[:] = np.array([12, 24, 36])\n",
    "    with segyio.create(new_seismic, spec) as nsegy:\n",
    "        nsegy.text[0] = segy.text[0]\n",
    "        nsegy.bin = segy.bin\n",
    "        nsegy.header = segy.header\n",
    "        nsegy.header.offset = np.array([12, 24, 36])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "trace count inconsistent with file size, trace lengths possibly of non-uniform",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-cfc7431726c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0msegyio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_seismic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnsegy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnsegy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moffsets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/test/lib/python3.7/site-packages/segyio/open.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(filename, mode, iline, xline, strict, ignore_geometry, endian)\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_segyio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0mfd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_segyio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msegyiofd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendians\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mendian\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m     \u001b[0mfd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msegyopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m     \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: trace count inconsistent with file size, trace lengths possibly of non-uniform"
     ]
    }
   ],
   "source": [
    "with segyio.open(new_seismic, \"r\") as nsegy:\n",
    "    print(nsegy.offsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "trace count inconsistent with file size, trace lengths possibly of non-uniform",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-b9c6726c51dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0msegyio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_seismic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnsegy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnsegy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moffsets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/test/lib/python3.7/site-packages/segyio/open.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(filename, mode, iline, xline, strict, ignore_geometry, endian)\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_segyio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0mfd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_segyio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msegyiofd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendians\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mendian\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m     \u001b[0mfd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msegyopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m     \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: trace count inconsistent with file size, trace lengths possibly of non-uniform"
     ]
    }
   ],
   "source": [
    "with segyio.open(new_seismic, \"r\", spec) as nsegy:\n",
    "    print(nsegy.offsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'No such field 2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-125-c448884e30d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_printoptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0msegyio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_seismic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r+\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mseg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;31m#seg.attributes(segyio.TraceField.offset)[0] = np.array([12,24,36])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m#print(seg.attributes(segyio.TraceField.offset)[0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/test/lib/python3.7/site-packages/segyio/field.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    354\u001b[0m         \"\"\"\n\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetfield\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'No such field 2'"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(threshold=np.inf)\n",
    "with segyio.open(new_seismic, \"r+\") as seg:\n",
    "    seg.header[0][34]\n",
    "    #seg.attributes(segyio.TraceField.offset)[0] = np.array([12,24,36])\n",
    "    #print(seg.attributes(segyio.TraceField.offset)[0])\n",
    "    #print(type(seg.attributes(segyio.TraceField.offset)[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros([1,1501])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T00:05:17.436554Z",
     "start_time": "2019-08-14T00:05:17.414959Z"
    }
   },
   "outputs": [],
   "source": [
    "angle_list = [12, 24, 36]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T00:05:47.374611Z",
     "start_time": "2019-08-14T00:05:46.208643Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T00:05:48.490083Z",
     "start_time": "2019-08-14T00:05:48.481743Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "sins = []\n",
    "for angle in angle_list:\n",
    "    sins += [np.sin(np.radians(angle)) * np.sin(np.radians(angle))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T00:05:52.535511Z",
     "start_time": "2019-08-14T00:05:52.510520Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.04322727117869955, 0.16543469682057088, 0.3454915028125263]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Youtube mp tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## introduction - first video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-15T20:05:52.955213Z",
     "start_time": "2019-08-15T20:05:52.911380Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process id 5182\n",
      "Process id 5185\n",
      "Process name: Process-26\n",
      "The number 1 square to 1\n",
      "Process id 5190\n",
      "Process name: Process-27\n",
      "Process id 5193\n",
      "The number 2 square to 4\n",
      "Process name: Process-28\n",
      "Process name: Process-29\n",
      "The number 4 square to 16\n",
      "The number 3 square to 9\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from multiprocessing import Process, current_process\n",
    "import numpy as np\n",
    "def square(number):\n",
    "    result = number * number\n",
    "    \n",
    "    # Print the process number\n",
    "    process_id = os.getpid()\n",
    "    print(f\"Process id {process_id}\")\n",
    "    \n",
    "    # Print process name\n",
    "    process_name =   current_process().name\n",
    "    print(f\"Process name: {process_name}\")\n",
    "    print(f\"The number {number} square to {result}\")\n",
    "          \n",
    "if __name__ == \"__main__\":\n",
    "    processes = []\n",
    "    numbers = np.arange(1,5)\n",
    "    \n",
    "    for number in numbers:\n",
    "        process = Process(target =square, args=(number, )) #object\n",
    "        processes.append(process)\n",
    "        \n",
    "        process.start() # Initiating the Process object "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## introduction - first video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-15T20:18:11.638961Z",
     "start_time": "2019-08-15T20:18:11.584748Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number 0 square to 0\n",
      "The number 0 square to 0\n",
      "The number 0 square to 0\n",
      "The number 0 square to 0\n",
      "The number 0 square to 0\n",
      "The number 1 square to 1\n",
      "The number 1 square to 1\n",
      "The number 1 square to 1\n",
      "The number 1 square to 1\n",
      "The number 1 square to 1\n",
      "The number 2 square to 4\n",
      "The number 2 square to 4\n",
      "The number 2 square to 4\n",
      "The number 2 square to 4\n",
      "The number 2 square to 4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import time\n",
    "from multiprocessing import Process, current_process\n",
    "import numpy as np\n",
    "def square(numbers):\n",
    "    for number in numbers:\n",
    "        time.sleep(0.5)\n",
    "        result = number * number\n",
    "        print(f\"The number {number} square to {result}\")    \n",
    "          \n",
    "if __name__ == \"__main__\":\n",
    "    processes = []\n",
    "    numbers = np.arange(3)\n",
    "   \n",
    "    # how many times the process should be applied\n",
    "    for i in range(5):\n",
    "        process = Process(target =square, args=(numbers, )) #object\n",
    "        processes.append(process)      \n",
    "        \n",
    "        process.start() # Initiating the Process object \n",
    "        \n",
    "    for process in processes:\n",
    "        process.join() # wait for all processes to be finished in order to continue\n",
    "        \n",
    "        # HAVENT WORKED WITH PROCESSORS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## locks - third video\n",
    "#Locks are useful to ensure that the operations goes the way we want, in the sequence we design... processes are independent, so this is a bother when we have a sequence: the first processes to finish will be the quicker one and this won't be necessary the first in our sequence. So using locks solve this issue: as long as the processes in sequence arent finished, the ones below the first wont be initiaized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-15T20:42:26.321707Z",
     "start_time": "2019-08-15T20:42:24.230058Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import time\n",
    "from multiprocessing import Process, Lock, Value\n",
    "\n",
    "def add_500_lock(total, lock):\n",
    "    for i in range(100):\n",
    "        lock.acquire()\n",
    "        time.sleep(0.01)\n",
    "        total.value += 5\n",
    "        lock.release()\n",
    "\n",
    "def sub_500_lock(total, lock):\n",
    "    for i in range(100):\n",
    "        lock.acquire()\n",
    "        time.sleep(0.01)\n",
    "        total.value -= 5\n",
    "        lock.release()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    total = Value(\"i\", 500)\n",
    "    lock = Lock()\n",
    "#    print(total)\n",
    "#    total = add_500_no_mp(total)\n",
    "#    print(total)\n",
    "#    total = sub_500_no_mp(total)\n",
    "#    print(total)\n",
    "    add_process =  Process(target = add_500_lock, args = (total,lock ))\n",
    "    sub_process =  Process(target = sub_500_lock, args = (total,lock ))\n",
    "    \n",
    "    add_process.start()\n",
    "    sub_process.start()\n",
    "\n",
    "    add_process.join()\n",
    "    sub_process.join()\n",
    "    \n",
    "    print(total.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## logging - fourth video\n",
    "make logs in the terminal of what's happening\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import time\n",
    "from multiprocessing import Process, Lock, Value\n",
    "\n",
    "def add_500_lock(total, lock):\n",
    "    for i in range(100):\n",
    "        lock.acquire()\n",
    "        time.sleep(0.01)\n",
    "        total.value += 5\n",
    "        lock.release()\n",
    "\n",
    "def sub_500_lock(total, lock):\n",
    "    for i in range(100):\n",
    "        lock.acquire()\n",
    "        time.sleep(0.01)\n",
    "        total.value -= 5\n",
    "        lock.release()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    total = Value(\"i\", 500)\n",
    "    lock = Lock()\n",
    "#    print(total)\n",
    "#    total = add_500_no_mp(total)\n",
    "#    print(total)\n",
    "#    total = sub_500_no_mp(total)\n",
    "#    print(total)\n",
    "    add_process =  Process(target = add_500_lock, args = (total,lock ))\n",
    "    sub_process =  Process(target = sub_500_lock, args = (total,lock ))\n",
    "    \n",
    "    add_process.start()\n",
    "    sub_process.start()\n",
    "\n",
    "    add_process.join()\n",
    "    sub_process.join()\n",
    "    \n",
    "    print(total.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pool - fifth video\n",
    "Pool distributes the process to the processor of a machine. Each processor runs independent process. Avoid serial algorithm \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-15T21:22:31.871823Z",
     "start_time": "2019-08-15T21:22:15.644880Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 10000 numbers took 5.514689683914185 time using mp\n",
      "Processing 10000 numbers took 10.686281681060791 time without using mp\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import time\n",
    "from multiprocessing import Pool\n",
    "\n",
    "def sum_square(number):\n",
    "    s = 0\n",
    "    for i in range(number):\n",
    "        s += i * i\n",
    "    return s\n",
    "\n",
    "def square_sum_mp(numbers):\n",
    "    \n",
    "    start_time =  time.time()\n",
    "    \n",
    "    p = Pool()\n",
    "    \n",
    "    # result is what the function returns. this store an iterable return in a list (map)\n",
    "    result = p.map(sum_square, numbers)\n",
    "    \n",
    "    # closes the process after the map is done\n",
    "    p.close()\n",
    "    # adds a processor to the working network ?\n",
    "    p.join()\n",
    "    \n",
    "    end_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"Processing {len(numbers)} numbers took {end_time} time using mp\")\n",
    "    \n",
    "\n",
    "def square_sum_no_mp(numbers):\n",
    "    start_time = time.time()\n",
    "    result = []\n",
    "    for i in numbers:\n",
    "        result.append(sum_square(i))\n",
    "        \n",
    "    end_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"Processing {len(numbers)} numbers took {end_time} time without using mp\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    numbers = range(10000)\n",
    "    \n",
    "    square_sum_mp(numbers)\n",
    "    square_sum_no_mp(numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## queue - fifth video\n",
    "share data structure amonf various processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-15T21:33:29.600956Z",
     "start_time": "2019-08-15T21:33:29.546250Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "4\n",
      "9\n",
      "16\n",
      "0\n",
      "1\n",
      "8\n",
      "27\n",
      "64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from multiprocessing import Process, Queue\n",
    "\n",
    "def square(numbers, queue):\n",
    "    for i in numbers:\n",
    "        queue.put(i * i)\n",
    "\n",
    "def cube(numbers, queue):\n",
    "    for i in numbers:\n",
    "        queue.put(i * i * i)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    numbers = range(5)\n",
    "    queue = Queue()\n",
    "    \n",
    "    square_process = Process(target = square, args = (numbers, queue))\n",
    "    cube_process = Process(target = cube, args = (numbers, queue))\n",
    "    \n",
    "    square_process.start()\n",
    "    cube_process.start()\n",
    "    \n",
    "    square_process.join()\n",
    "    cube_process.join()\n",
    "    \n",
    "    while not queue.empty():\n",
    "        print(queue.get())\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "1- Pool allows me can distribute functions (processes) to my pc's cores\n",
    "2 - Queue allows me to store into an object some iterables of whatever function calls the object. Then its possible to print or store this data   \n",
    "    \n",
    "With 1 and 2 in mind, i might distribute functions to my cores while each store the return in queue?? On queue could be the inputs to store AVO attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST:\n",
    "to apply a random functions given a pool of workers (quantity of cores by default) then returning a list of warever to see what's going on\n",
    "\n",
    "IT FUCKING WORK!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-15T22:14:57.339057Z",
     "start_time": "2019-08-15T22:14:57.328157Z"
    }
   },
   "outputs": [],
   "source": [
    "def warever(end):\n",
    "    for i in range(1, end):\n",
    "        yield [i, i*2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-15T22:14:57.556401Z",
     "start_time": "2019-08-15T22:14:57.551626Z"
    }
   },
   "outputs": [],
   "source": [
    "x = warever(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-15T22:49:01.216919Z",
     "start_time": "2019-08-15T22:48:57.404221Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't pickle generator objects",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-98-7672749b6190>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"name\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tesis/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m         '''\n\u001b[0;32m--> 290\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tesis/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    681\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 683\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tesis/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36m_handle_tasks\u001b[0;34m(taskqueue, put, outqueue, pool, cache)\u001b[0m\n\u001b[1;32m    455\u001b[0m                         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m                         \u001b[0mput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m                         \u001b[0mjob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tesis/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_writable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ForkingPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrecv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlength\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tesis/lib/python3.7/multiprocessing/reduction.py\u001b[0m in \u001b[0;36mdumps\u001b[0;34m(cls, obj, protocol)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetbuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: can't pickle generator objects"
     ]
    }
   ],
   "source": [
    "def operations(list_of_values, name):\n",
    "    print(f\"taking {list_of_values[0]},{list_of_values[1]}\")\n",
    "    number = list_of_values[0]\n",
    "    suma = list_of_values[0] + list_of_values[1]\n",
    "    rest = list_of_values[0] - list_of_values[1]\n",
    "    mult = list_of_values[0] * list_of_values[1]\n",
    "    div = list_of_values[0] / list_of_values[1]\n",
    "    print(f\"Finishing using {list_of_values[0]},{list_of_values[1]}\")\n",
    "    result = [name, number, suma, rest, mult, div]\n",
    "    return(result)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    p = Pool()\n",
    "    r = p.map(operations, [x,\"name\"])\n",
    "    \n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tesis",
   "language": "python",
   "name": "tesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
